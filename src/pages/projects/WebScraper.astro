---
import Layout from '../../layout/Layout.astro';
import GitHub from '../../components/icons/GitHub.astro';
import Breadcrumbs from '../../components/Breadcrumbs.astro';
import { getProject } from '../../data/projects';

const project = getProject('WebScraper')!;
const siteOrigin = 'https://cristianopinto.com';
const jsonLd = {
  '@context': 'https://schema.org',
  '@type': 'CreativeWork',
  name: project.title,
  description: project.tagline,
  url: `${siteOrigin}/projects/WebScraper`,
  author: { '@type': 'Person', name: 'Cristiano Pinto' },
  dateCreated: project.date,
};
---

<Layout title={`${project.title} – Cristiano Pinto`} description={project.tagline} image="/data-scraper.png" jsonLd={jsonLd}>
  <div class="projects-wrapper back">
      <Breadcrumbs items={[
        { label: 'Home', href: '/' },
        { label: 'Projects', href: '/projects' },
        { label: project.title }
      ]} />
      <header class="detail-header fade-in">
        <a href="/projects" class="back-link">
          <span class="arrow">←</span> Back to Projects
        </a>
        <h1>{project.title}</h1>
        <p class="tagline">{project.tagline}</p>
      </header>

      <div class="content-grid fade-in-delay">
        
        <main class="project-body">
          <div class="project-hero-image">
             <img src="/data-scraper.png" alt="Web Scraper project screenshot" style="width: 100%; height: 100%; display: block;"/>
          </div>

          <div class="text-content">
            <h3>What Is This?</h3>
            <p>
              A scraper that trawls AO3 and FanFiction.net looking for stories that match specific criteria. Keyword filtering handles the obvious rejects, then a local LLM decides if the rest are actually worth reading.
            </p>
            <p>
              Matches get logged to a Google Sheet for later. The whole thing runs locally—no API costs, no rate limits.
            </p>

            <h3>The Two-Stage Filter</h3>
            <p>
              LLM inference is slow. Running every story through one would take forever. So the pipeline has two stages:
            </p>
            <ol>
              <li><strong>Keyword filter</strong> — Fast substring matching against summaries. No keywords? Skip immediately.</li>
              <li><strong>LLM classification</strong> — Stories that pass stage one get sent to Ollama for a real judgment call. The model returns True or False.</li>
            </ol>
            <p>
              This cuts LLM calls by 50-90% depending on how selective your keywords are. Most stories don't make it past stage one.
            </p>

            <h3>Browser Automation</h3>
            <p>
              Standard Selenium gets blocked instantly on these sites. SeleniumBase in undetected-chromedriver mode gets around that—it masks the automation fingerprints that bot detection looks for.
            </p>
            <p>
              The scraper handles CAPTCHAs automatically via <code>uc_gui_click_captcha()</code>, and <code>uc_open_with_reconnect()</code> retries on flaky connections. DOM extraction uses CSS selectors to pull titles and summaries from each page.
            </p>

            <h3>Site-Specific Scrapers</h3>
            <p>
              Each site needs its own module because the DOM structure differs:
            </p>
            <ul>
              <li><strong>AO3</strong> — Filters by fandom tag, 80k+ word count, sorted by update date. Pulls from <code>div.header.module</code> and <code>.userstuff.summary</code>.</li>
              <li><strong>FanFiction.net</strong> — Filters by rating, length, and language. Uses <code>.stitle</code> and <code>.z-indent.z-padtop</code>.</li>
            </ul>
            <p>
              If either site changes their markup, the selectors break. That's the fragile part.
            </p>

            <h3>Local LLM</h3>
            <p>
              Classification runs through Ollama—phi4, phi4-mini, or deepseek-r1 depending on what you've got pulled. Temperature is set to 0 for deterministic outputs. The prompt tells the model to respond with a single word: True or False.
            </p>
            <p>
              Parsing is just string matching. If the model gets chatty, it breaks. But with the right prompt, it doesn't.
            </p>

            <h3>Output</h3>
            <p>
              Matches append to a Google Sheet via gspread with OAuth2 service account auth. Each row gets title, summary, page number, and URL. Easy to scan through later and pick what to actually read.
            </p>

            <h3>Resumable Runs</h3>
            <p>
              Start and end pages are configurable constants. If a scrape gets interrupted, bump the start page and run again. Not sophisticated, but it works.
            </p>
          </div>
        </main>

        <aside class="project-sidebar">
          
          <div class="meta-block">
            <span class="meta-label">Role</span>
            <span class="meta-value">{project.role}</span>
          </div>

          <div class="meta-block">
            <span class="meta-label">Timeline</span>
            <span class="meta-value">{project.date}</span>
          </div>

          <div class="meta-block">
            <span class="meta-label">Stack</span>
            <div class="tech-stack-wrap">
              {project.stack.map(tech => (
                <span class="tech-tag">{tech}</span>
              ))}
            </div>
          </div>

          <div class="meta-block">
            <span class="meta-label">Features</span>
            <div class="tech-stack-wrap">
              <span class="tech-tag">Two-Stage Filter</span>
              <span class="tech-tag">Local LLM</span>
              <span class="tech-tag">CAPTCHA Handling</span>
              <span class="tech-tag">Sheets Export</span>
            </div>
          </div>

          <div class="meta-block">
            <span class="meta-label">Sites</span>
            <span class="meta-value">AO3, FanFiction.net</span>
          </div>

          <div class="meta-block">
            <span class="meta-label">LLM</span>
            <span class="meta-value">Ollama (phi4, deepseek-r1)</span>
          </div>

          <div class="action-buttons">
            <a href={project.repoUrl} target="_blank" rel="noopener noreferrer" class="action-btn outline">
              <span class="icon"><GitHub width={20} height={20} /></span>
              View Code
            </a>
          </div>

        </aside>

      </div>

  </div>
</Layout>